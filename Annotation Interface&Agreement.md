# Annotation Interface&Agreement

We implement a rigorous selection protocol for the entities collected and their corresponding images. Specifically, we require three annotators to filter entities and images. The interface for this manual selection is illustrated in Figure 1,2,3, where each entity and images are subjected to a meticulous human review. Initially, we amassed a diverse collection of 1,500 entities across various categories. Subsequently, we evaluated each entity and its images from four critical perspectives: Observable, Specific, Unambiguous, and Unitary. If an entity fails to meet the standards of being Observable, Specific, or Unambiguous, it is entirely removed from the collection. Similarly, if any specific image associated with an entity not adhere to the criterion of Unity, that image is excluded in the editing step. This selection and evaluation process involves three human annotators for each entity and image. Retention within the dataset is contingent upon a unanimous decision by all three annotators. If consensus is not reached, the evaluation is repeated until a unanimous decision is achieved.
<p align="center">
  <img src="images/Figure1.jpg" alt="Figure1" width="500" height="350">
  <br>
  <strong><p align="center">Figure 1: Manual evaluation interface</p></strong>
</p>

<p align="center">
  <img src="images/Figure2.jpg" alt="Figure2" width="500" height="350">
  <strong><p align="center">Figure 2: Manual evaluation interface</p></strong>
</p>
<p align="center">
  <img src="images/Figure3.jpg" alt="Figure3" width="500" height="350">
  <strong><p align="center">Figure 3: Manual evaluation interface</p></strong>
</p>
